category: Text Generation
description: >-
  Use a local install of LM Studio to generate text from a prompt, using
  whatever model is currently loaded by the program.
meta:
  source:
    title: LM-Studio Integration
    links:
      OpenAI Chat Completions Hello World (Python): >-
        https://github.com/lmstudio-ai/examples/tree/main/Hello%2C%20world%20-%20OpenAI%20python%20client
      LM-Studio One-click-installer (win/mac): https://lmstudio.ai/
    summary: Run local LLMs
title: Generate Text (LLM Studio)
apiNamespace: lm-studio
apiOperationId: createChatCompletion
displayNamespace: lm-studio
displayOperationId: simpleGenerateTextViaLmStudio
scripts:
  hideExcept:inputs:
    - prompt
    - temperature
    - instruction
    - max_tokens
  hideExcept:outputs:
    - text
    - usage
inputs:
  max_tokens:
    type: number
    title: Max Tokens
    description: >-
      The randomness regulator, higher for more creativity, lower for more
      structured, predictable text. -1 to disable.
    default: -1
    minimum: -1
  temperature:
    title: Temperature
    description: >-
      The randomness regulator, higher for more creativity, lower for more
      structured, predictable text.
    default: 0.3
    minimum: 0
    maximum: 1
    step: 0.1
  instruction:
    default: You are a helpful bot. You can help people by answering their questions.
    type: string
  prompt:
    required: true
    type: string
  messages:
    scripts:
      jsonata: >-
        [{"role":"system", "content": $string(instruction) }, {"role":"user",
        "content": $string(prompt) }]
      delete:
        - prompt
        - instruction
outputs:
  usage:
    title: Usage Info
  text:
    title: Text
    scripts:
      jsonata: choices[0].message.content
    type: string
