category: Text Generation
description: >-
  Use a local install of LM Studio to generate text from a prompt, using
  whatever model is currently loaded by the program.
meta:
  source:
    title: LM-Studio Integration
    links:
      OpenAI Chat Completions Hello World (Python): >-
        https://github.com/lmstudio-ai/examples/tree/main/Hello%2C%20world%20-%20OpenAI%20python%20client
      LM-Studio One-click-installer (win/mac): https://lmstudio.ai/
    summary: Run local LLMs
title: Generate Text (Simple)
apiNamespace: lm-studio
apiOperationId: createChatCompletion
displayNamespace: lm-studio
displayOperationId: simpleGenerateTextViaLmStudio
scripts:
  hideExcept:inputs:
    - prompt
    - instruction
    - model
    - max_tokens
  hideExcept:outputs:
    - text
inputs:
  temperature:
    description: >-
      The randomness regulator, higher for more creativity, lower for more
      structured, predictable text.
    default: 0.7
    minimum: 0
    maximum: 2
    step: 0.01
  instruction:
    default: You are a helpful bot. You can help people by answering their questions.
    type: string
  prompt:
    description: A text description that guides the text generation process.
    required: true
    type: AlpineTextComponent
  messages:
    scripts:
      jsonata: >-
        [{"role":"system", "content": $string(instruction) }, {"role":"user",
        "content": $string(prompt) }]
      delete:
        - prompt
        - instruction
  max_tokens:
    description: The maximum number of tokens to generate.
    default: 2048
outputs:
  text:
    scripts:
      jsonata: choices[0].message.content
    type: string
    customSocket: text
