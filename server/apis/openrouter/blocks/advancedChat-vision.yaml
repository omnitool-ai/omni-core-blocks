category: Text Generation
description: >-
  A unified API for LLMs. Let you choose your prefered LLM model, or let OpenRouter route for you.
title: OpenRouter LLM - Vision
apiNamespace: openrouter
apiOperationId: chatCompletions
displayNamespace: openrouter
displayOperationId: advancedChatVision
# scripts:
#   hideExcept:inputs:
#     - prompt
#     - instruction
#     - model
#     - fallback
#     - X-Title
#     - temperature
#     - json_mode
#     - top_p
#     - seed
inputs:
  HTTP-Referer:
    hidden: true
  X-Title:
    title: App Title
    description: >-
      The title of your app. This will show on openrouter.ai/activity dashboard.
    default: Omnitool
  temperature:
    title: Temperature
    type: number
    description: >-
      The randomness regulator, higher for more creativity, lower for more
      structured, predictable text.
    minimum: 0
    maximum: 1
    step: 0.1
    default: 0.3
  prompt:
    required: true
    type: string
    customSocket: text
  instruction:
    type: string
    customSocket: text
    default: You are a helpful bot.  You can help people by answering their questions.
  messages:
    hidden: true
    scripts:
      jsonata: >-
        [
          {
            "role": "system",
            "content": [
              {
                "type": "text",
                "text": $string(instruction)
              }
            ]
          },
          {
            "role": "user",
            "content": [
              {
                "type": "text",
                "text": $string(prompt)
              },
              {
                "type": "image_url",
                "image_url": {
                  "url": "data:image/jpeg;base64," & $string(images)
                }
              }
            ]
          }
        ]
      delete:
        - prompt
        - instruction
        - images
  model:
    title: Model
    default: openai/gpt-4-vision-preview
    choices:
      block: openrouter.listModels
      cache: user
      map:
        root: models
        filter:
          value: ".*vision.*"
  fallback_model:
    title: Fallback Model
    type: string
    customSocket: text
    default: openrouter/auto
    description: >-
      When fallback mode is enabled, OpenRouter will automatically switch to a fallback model if the selected model encounters an error.
    scripts:
      jsonata: >- 
        $.fallback = true ? fallback_model : undefined
    choices:
      block: openrouter.listModels
      cache: user
      map:
        root: models
        filter:
          value: ".*vision.*"
  models:
    hidden: true
    scripts:
      jsonata: >-
        $exists(fallback_model) ? [model, fallback_model] : [model]
      delete:
        - fallback_model
        - model
  images:
    required: true
    title: Images
    type: string
    customSocket: image
    socketOpts:
      format: base64
  seed:
    title: Seed
    type: integer
    description: >-
      If supported by the model, set the seed parameter to any integer of your choice and use the same value across requests you'd like deterministic outputs for. Note that this is still in beta for gpt models.
  # json_mode:
  #   title: JSON Mode
  #   description: >-
  #     If enabled, the output will be formatted in JSON if supported by the model e.g. gpt-4-1106-preview and gpt-3.5-turbo-1106. Ensure that your prompt includes the word 'json' in some form; failure to do so may result in an error.
  #   type: boolean
  #   default: false
  # response_format:
  #   type: object
  #   hidden: true
  #   scripts:
  #     jsonata: >-
  #       { "type": $boolean(json_mode) ? "json_object" : "text" }
  #     delete:
  #       - json_mode
  # top_p:
  #   title: Top P
  #   type: number
  #   description: >-
  #     Implements nucleus sampling, where the model considers only tokens whose cumulative probability exceeds the specified `top_p` threshold.
  #     Like `temperature`, this controls the diversity of the model's output.
  #   default: 1
  #   minimum: 0
  #   maximum: 1
  #   step: 0.05
  max_tokens:
    type: number
    minimum: 1
    maximum: 4096
    default: 4096
    step: 1
  stream:
    hidden: true
    type: boolean
    default: false
  fallback:
    title: Fallback Mode
    type: boolean
    default: false
    description: >-
      If the model you selected returns an error, OpenRouter will try to use the fallback model instead. If no fallback model specified, OpenRouter will try the most appropriate open-source model available, with pricing less than the primary model (or very close to it). 
  route:
    hidden: true
    scripts:
      jsonata: >- 
        $.fallback = true ? "fallback" : undefined
      delete:
        - fallback

outputs:
  answer:
    scripts:
      jsonata: choices[0].message.content
    type: string
    customSocket: text
  usage:
    title: Usage
    type: object
  model:
    scripts:
      jsonata: model
    type: string
    customSocket: text
  gen_id:
    title: Gen ID
    scripts:
      jsonata: id
    type: string
    customSocket: text
  system_fingerprint: 
    title: Seed
    type: integer
  choices:
    hidden: true
